{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Testing regular expressions for equivalence\"\n",
        "author: \"Martin Ong\"\n",
        "date: \"2024-1-12\"\n",
        "format: \n",
        "  html:\n",
        "    toc: true\n",
        "    embed-resources: true\n",
        "    code-fold: false\n",
        "    code-tools: true\n",
        "    code-line-numbers: true\n",
        "    number-sections: true\n",
        "---"
      ],
      "id": "1d27ed1c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from __future__ import annotations\n",
        "from collections import defaultdict, deque\n",
        "from typing import Generic, Literal, Protocol, Self, TypeVar\n",
        "from itertools import chain, combinations, product\n",
        "from copy import deepcopy\n",
        "\n",
        "\n",
        "EMPTYSET = \"\\u2205\"\n",
        "EPSILON = \"\\u03b5\"\n",
        "\n",
        "ALPHABET = \"ab\"\n",
        "EXTENDED_ALPHABET = f\"ab{EPSILON}\"\n",
        "T = TypeVar(\"T\")\n",
        "S = TypeVar(\"S\")"
      ],
      "id": "911bd569",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Equivalence\n",
        "Any two languages (sets of strings) are equivalent if they each contain\n",
        "the same strings. Often, when working with regular languages, we deal with\n",
        "objects which recognise a particular language, however it is not immediately\n",
        "clear from looking at such an object what the language it recognises actually\n",
        "is.\n",
        "\n",
        "A common problem when dealing with such objects is determining whether two\n",
        "different objects are equivalent, in the sense that they recognise the same\n",
        "language.\n",
        "\n",
        "In this post, we will focus on finite automata. <!-- TODO: reword -->\n"
      ],
      "id": "01de8805"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class Automaton(Protocol, Generic[T, S]):\n",
        "    \"\"\"\n",
        "    T: type of a state\n",
        "    S: type of a state's transition table\n",
        "    \"\"\"\n",
        "    start: T\n",
        "    states: set[T]\n",
        "    final: set[T]\n",
        "    transitions: dict[T, S]\n",
        "\n",
        "    def add_state(self, transitions: S) -> None:\n",
        "        ...\n",
        "\n",
        "    def make_final(self, state: T) -> None:\n",
        "        assert state in self.states\n",
        "        self.final.add(state)\n",
        "\n",
        "    def update(self, state: T, transitions: S) -> None:\n",
        "        self.transitions[state] = transitions\n",
        "\n",
        "    def evaluate(self, s: str) -> bool:\n",
        "        ..."
      ],
      "id": "5184fe0e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deterministic Finite Automata\n",
        "Deteriministic finite automata (DFAs) are one such object which behave nicely.\n",
        "It is well known that every DFA recognises a regular language, and every regular\n",
        "language is recognised by some DFA. Thus, we will begin by trying to compare\n",
        "two DFAs for equivalence.\n",
        "\n",
        "We can represent a DFA with the following python class"
      ],
      "id": "46474bf3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class DFA(Automaton[int, dict[str, int]]):\n",
        "    next_state: int\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        self.transitions = {}\n",
        "        self.start = 0\n",
        "        self.states = { self.start }\n",
        "        self.final = set()\n",
        "        self.next_state = 1\n",
        "\n",
        "    def add_state(self, transitions: dict[str, int]) -> None:\n",
        "        self.states.add(self.next_state)\n",
        "        self.transitions[self.next_state] = transitions\n",
        "        self.next_state += 1\n",
        "\n",
        "    def evaluate(self, s: str) -> bool:\n",
        "        curr = self.start\n",
        "        for c in s:\n",
        "            curr = self.transitions[curr][c]\n",
        "        return curr in self.final"
      ],
      "id": "e0924721",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this implementation, the `add_state` function creates a new state using the\n",
        "next unused integer as the new state ID.\n",
        "\n",
        "## Equivalence and Emptiness <!-- TODO: rename this -->\n",
        "Consider two DFAs, $D_1$ and $D_2$. Now suppose that the languages recognised\n",
        "by the DFAs is given by $L_1$ and $L_2$ respectively.\n",
        "\n",
        "If the DFAs are equivalent, then every string in $L_1$ must be in $L_2$. That is,\n",
        "the automata agree on every string.\n",
        "\n",
        "However, if they are not equivalent, then there exists at least one string which\n",
        "is recognised by one DFA and not the other.\n",
        "\n",
        "Thinking about this in set notation (remember that languages are just sets), \n",
        "we have that if $D_1$ and $D_2$ are not equivalent, then there is a string\n",
        "$x$ such that $x \\in L_1 \\cap L_2^c$ or $x \\in L_1^c \\cap L_2$.\n",
        "\n",
        "Hence, two DFAs are equivalent if the symmetric difference $$(L_1 \\cap L_2^2) \\cup (L_1^c \\cap L_2)$$\n",
        "of the languages they recognise is empty; i.e. there is no string which is in the language\n",
        "of one DFA and not the other.\n",
        "\n",
        "## Boolean operations with automata\n",
        "\n",
        "### Union\n",
        "Given two DFA, we want to be able to construct a new DFA which recognises\n",
        "the language of strings which is recognised by either of the two input DFAs.\n",
        "The standard way to do this is via a \"product construction\".\n",
        "\n",
        "The idea behind a product construction is to create a new DFA which essentially\n",
        "runs both DFA at once on the same string, and then checks if either is in a final\n",
        "state at the end of the run.\n",
        "\n",
        "To do this, we need our new DFA to keep track of the state each DFA is in at each\n",
        "step. We can achieve this by storing the pair of the two states the two DFAs are in\n",
        "as the current state of our new DFA.\n",
        "\n",
        "If the states of the two DFAs are given by $Q_1$ and $Q_2$, then\n",
        "our new DFA should have states $Q_1 \\times Q_2$.\n",
        "\n",
        "Then, since we want to accept any string which is accepted by any of the two DFAs,\n",
        "any state pair which contains at least one final state in the original DFAs\n",
        "should be marked as final.\n",
        "\n",
        "[DIAGRAM HERE]\n",
        "\n",
        "In code, this would be"
      ],
      "id": "9158ddde"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class DFA(DFA):\n",
        "    def union(self, dfa: DFA) -> DFA:\n",
        "        res = DFA()\n",
        "\n",
        "        state_pairs = list(product(self.states, dfa.states))\n",
        "\n",
        "        res.start = state_pairs.index((self.start, dfa.start))\n",
        "        res.states = set(range(len(state_pairs)))\n",
        "        res.final = set(i for i in res.states if state_pairs[i][0] in self.final or state_pairs[i][1] in dfa.final)\n",
        "        res.next_state = len(state_pairs)\n",
        "        res.transitions = {state: dict() for state in res.states}\n",
        "\n",
        "        for state in res.states:\n",
        "            for a in ALPHABET:\n",
        "                res.transitions[state][a] = state_pairs.index((\n",
        "                    self.transitions[state_pairs[state][0]][a],\n",
        "                    dfa.transitions[state_pairs[state][1]][a]\n",
        "                ))\n",
        "\n",
        "        return res"
      ],
      "id": "33910a95",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Intersection\n",
        "To find a DFA recognising the intersection of the languages of two DFA, we only\n",
        "need to slightly modify the algorithm for the union construction.\n",
        "\n",
        "In particular, after running the DFA with state pairs,  <!-- TODO: reword -->\n",
        "we only need to change the choice of final states.\n",
        "\n",
        "For the intersection case, we only want to accept strings which are accepted\n",
        "by both DFAs, so the final states should be the states where each of the states\n",
        "in the pair are final states in the original DFAs.\n",
        "\n",
        "In python, this would be "
      ],
      "id": "1f631d84"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class DFA(DFA):\n",
        "    def intersection(self, dfa: DFA) -> DFA:\n",
        "        res = DFA()\n",
        "\n",
        "        state_pairs = list(product(self.states, dfa.states))\n",
        "\n",
        "        res.start = state_pairs.index((self.start, dfa.start))\n",
        "        res.states = set(range(len(state_pairs)))\n",
        "        # Notice the 'or' has become an 'and' on this line\n",
        "        res.final = set(i for i in res.states if state_pairs[i][0] in self.final and state_pairs[i][1] in dfa.final)\n",
        "        res.next_state = len(state_pairs)\n",
        "        res.transitions = {state: dict() for state in res.states}\n",
        "\n",
        "        for state in res.states:\n",
        "            for a in ALPHABET:\n",
        "                res.transitions[state][a] = state_pairs.index((\n",
        "                    self.transitions[state_pairs[state][0]][a],\n",
        "                    dfa.transitions[state_pairs[state][1]][a]\n",
        "                ))\n",
        "\n",
        "        return res"
      ],
      "id": "0b72193e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Complement\n",
        "Now we want to construct a DFA recognising the complement language of some\n",
        "given DFA. That is, a DFA which accepts every string that is rejected by the\n",
        "original DFA.\n",
        "\n",
        "Since we just want to switch the evaluation of the DFA on every input, it suffices\n",
        "to switch the final and non-final states.\n",
        "\n",
        "In python, this would look like"
      ],
      "id": "181e01cd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class DFA(DFA):\n",
        "    def complement(self) -> DFA:\n",
        "        dfa = deepcopy(self)\n",
        "        dfa.final = self.states - self.final\n",
        "        return dfa"
      ],
      "id": "9d295087",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Symmetric Difference\n",
        "Recall that the symmetric difference of two languages $L_1$ and $L_2$ is given\n",
        "by $$(L_1 \\cap L_2^c) \\cup (L_1^c \\cap L_2)$$. Since we already know how to construct\n",
        "DFAs for the union, intersection and complement operations, we can compute\n",
        "the symmetric difference by combining the constructions together.\n"
      ],
      "id": "27d2318c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class DFA(DFA):\n",
        "    def symmetric_difference(self, dfa: DFA) -> DFA:\n",
        "        self_not_d = self.intersection(dfa.complement())\n",
        "        not_self_d = self.complement().intersection(dfa)\n",
        "\n",
        "        return self_not_d.union(not_self_d)"
      ],
      "id": "d1d8921a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Equivalence and Emptiness\n",
        "Now, given two DFA we can construct a new DFA which recognises all of the strings\n",
        "on which the two original DFA disagree. It suffices to determine whether or not\n",
        "this new DFA actually accepts any strings. If it doesn't recognise any strings, then\n",
        "then two original DFA recognise the same language.\n",
        "\n",
        "Since all we want is to find a single string which the DFA accepts, we just need to\n",
        "find a path from the start state which leads to a final state, and then the DFA \n",
        "will accept the string formed by adding one character for each transition along \n",
        "this path, starting from the start state.\n",
        "\n",
        "[DIAGRAM]\n",
        "\n",
        "We will do so with a BFS traversal."
      ],
      "id": "43667c27"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class DFA(DFA):\n",
        "    def is_empty(self) -> bool:\n",
        "        seen = set()\n",
        "        queue: deque[int] = deque([self.start])\n",
        "\n",
        "        while len(queue) > 0:\n",
        "            curr = queue.popleft()\n",
        "            if curr in self.final:\n",
        "                return False\n",
        "            if curr in seen:\n",
        "                continue\n",
        "            seen.add(curr)\n",
        "\n",
        "            for a in ALPHABET:\n",
        "                state = self.transitions[curr][a]\n",
        "                queue.append(state)\n",
        "\n",
        "        return True"
      ],
      "id": "19642099",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we can put everything together to obtain an equivalence algorithm for DFAs!\n"
      ],
      "id": "dc843a43"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class DFA(DFA):\n",
        "    def is_equivalent(self, dfa: DFA) -> bool:\n",
        "        return self.symmetric_difference(dfa).is_empty()"
      ],
      "id": "2b31560c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generalising to NFAs\n",
        "Whilst DFAs are generally well behaved and have nice closure properties, as we saw\n",
        "in the boolean operations section, often it is easier to represent languages with\n",
        "more general objects. One such object is a nondeterministic finite automata, which\n",
        "is a generalisation of DFA where states may have more than one outgoing transition for each\n",
        "character, and a path to the final state is chosen nondeterministically.\n"
      ],
      "id": "4723b439"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class NFA(Automaton[int, dict[str, set[int]]]):\n",
        "    next_state: int\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        self.transitions = {}\n",
        "        self.start = 0\n",
        "        self.states = { self.start }\n",
        "        self.final = set()\n",
        "        self.next_state = 1\n",
        "\n",
        "    def add_state(self, transitions: dict[str, set[int]]) -> None:\n",
        "        self.states.add(self.next_state)\n",
        "        self.transitions[self.next_state] = transitions\n",
        "        self.next_state += 1\n",
        "        \n",
        "    def evaluate(self, s: str) -> bool:\n",
        "        curr = { self.start }\n",
        "        for c in s:\n",
        "            curr = set().union(\n",
        "                *(self.transitions[state][c] for state in curr)\n",
        "            )\n",
        "        return len(curr & self.final) > 0"
      ],
      "id": "a9608718",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[diagram of an NFA]\n",
        "\n",
        "Consider the NFA shown above. If it is run on the string 'abba', [say what states it is in]\n",
        "\n",
        "Notice that we have just applied a deterministic algorithm to determine whether\n",
        "or not an NFA accepts a given string: we keep track at each step of which states\n",
        "the NFA could possibly be in, and then accept the string if one of the possible\n",
        "ending states is final in the original NFA.\n",
        "\n",
        "We can create a DFA to complete this process in a similar manner to the product construction\n",
        "for union and intersection, but now we need to keep track of a set of possible\n",
        "states which might not be of a constant length at all times.\n",
        "\n",
        "To achieve this, we can create a new DFA with states labelled by the powerset\n",
        "of the set of states of the original DFA. Recall that the powerset of a set\n",
        "is the set of all subsets, so the powerset of $\\{1, 2, 3\\}$ would be\n",
        "$$\\{\\{\\}, \\{1\\}, \\{2\\}, \\{3\\}, \\{1,2\\}, \\{1,3\\}, \\{2,3\\}, \\{1,2,3\\}\\}.$$\n",
        "\n",
        "Since we want the current state of this new DFA to store the set of states that\n",
        "the NFA could be in, the choice of transitions follows naturally: for each\n",
        "character $a$, the $a$-transition from each state should be the set of states\n",
        "reachable from any state in the current set along a single $a$-transition in\n",
        "the original NFA.\n",
        "\n",
        "This way, the current state will always represent the set of possible states \n",
        "the NFA could be upon reading the current character.\n",
        "\n",
        "Finally, the final states in the new DFA should be the sets of states which\n",
        "contain at least one final state in the NFA, since this would correspond to\n",
        "the possiblilty of ending in a final state in the original NFA.\n",
        "\n",
        "We can program this so called 'determinisation' of the NFA as follows."
      ],
      "id": "90631d13"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class NFA(NFA):\n",
        "    def determinise(self) -> DFA:\n",
        "        def powerset(s: set[T]) -> list[tuple[T, ...]]:\n",
        "            return list(chain.from_iterable(set(combinations(s, r)) for r in range(len(s)+1)))\n",
        "\n",
        "        dfa = DFA()\n",
        "\n",
        "        subsets = powerset(self.states)\n",
        "\n",
        "        dfa.start = subsets.index((self.start,))\n",
        "        dfa.states = set(range(len(subsets)))\n",
        "        dfa.final = set(i for i in dfa.states if len(set(subsets[i]) & self.final) > 0)\n",
        "        dfa.transitions = {state: dict() for state in dfa.states}\n",
        "        dfa.next_state = len(subsets)\n",
        "\n",
        "        for state, subset in enumerate(subsets):\n",
        "            for a in ALPHABET:\n",
        "                result = set().union(*(self.transitions[s].get(a, set()) for s in subset))\n",
        "                dfa.transitions[state][a] = subsets.index(\n",
        "                    tuple(sorted(result))\n",
        "                )\n",
        "\n",
        "        return dfa"
      ],
      "id": "c7a1bfab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "However, there is a problem with this algorithm. If you look carefully,\n",
        "you will notice that we never handled $\\varepsilon$-transitions. If an NFA contains\n",
        "$\\varepsilon$-transitions, then after taking an $a$-transition it might be able to\n",
        "reach extra states that aren't included in the target state in the DFA!\n",
        "\n",
        "To fix this issue, we can first remove all $\\varepsilon$-transitions from the\n",
        "NFA before running the determinisation algorithm.\n",
        "\n",
        "## Removing $\\varepsilon$ States\n",
        "Consider the following NFA which contains two $\\varepsilon$-transitions.\n",
        "\n",
        "[diagram]\n",
        "\n",
        "If we want to construct a new NFA which is equivalent to this NFA but doesn't\n",
        "contain any $\\varepsilon$-transitions, we should construct additional transitions\n",
        "from some state $s$ to a state $t$ if $t$ is reachable from $s$ using at most\n",
        "one non-$\\varepsilon$-transition.\n",
        "\n",
        "For this example, consider the initial state $q_0$. Its only outgoing transitions\n",
        "are an $a$-transition pointing to $q_1$ and a $b$-transition pointing at $q_3$.\n",
        "Now, $q_3$ only has one outgoing transition, and it is not an $\\varepsilon$-transition\n",
        "so there will be no additional states reachable along this path.\n",
        "However, $q_1$ has two outgoing $\\varepsilon$-transitions, pointing to $q_3$\n",
        "and $q_2$. Thus, in the equivalent NFA without $\\varepsilon$-transitions\n",
        "we are constructing, there should be additional $a$-transitions from $q_0$ to\n",
        "$q_2$ and $q_3$, and the original transitions should also remain in the new NFA. \n",
        "\n",
        "We can program this nicely using a DFS."
      ],
      "id": "f2b1d48c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class NFA(NFA):\n",
        "    def remove_epsilon(self) -> NFA:\n",
        "        nfa = deepcopy(self)\n",
        "        nfa.transitions = {state: dict() for state in self.states}\n",
        "\n",
        "        for state in self.states:\n",
        "            seen: set[int] = set()\n",
        "            final = [False]\n",
        "            # dfs to get all states reachable by exactly one non-epsilon transition\n",
        "            def helper(curr: int) -> None:\n",
        "                if curr not in seen:\n",
        "                    seen.add(curr)\n",
        "                    if curr in self.final:\n",
        "                        final[0] = True\n",
        "                    for a, targets in self.transitions[curr].items():\n",
        "                        if a == EPSILON:\n",
        "                            for target in targets:\n",
        "                                helper(target)\n",
        "                        else:\n",
        "                            nfa.transitions[state][a] = \\\n",
        "                                nfa.transitions[state].get(a, set()) | targets\n",
        "            helper(state)\n",
        "            if final[0]:\n",
        "                nfa.final.add(state)\n",
        "\n",
        "        return nfa"
      ],
      "id": "1c8b109e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "-- show algorithm for nfa -> dfa\n",
        "something like: (maybe needds __super__)"
      ],
      "id": "b053866b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class NFA(NFA):\n",
        "    def determinise1(self) -> DFA:\n",
        "        return self.remove_epsilon().determinise()"
      ],
      "id": "9f2c7a46",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Regex Equivalence\n",
        "Now that we are able to test both NFAs and DFAs for equivalence, we will move\n",
        "on to generalising further so that we can also test regex for equivalence.\n",
        "\n",
        "In the same way that we generalised to NFAs from DFA equivalence by showing how\n",
        "to convert an NFA into an equivalent DFA, we will show how to convert a regular\n",
        "expression into an equivalent NFA, and then employ the previous techniques\n",
        "to test if the two NFAs are equivalent.\n",
        "\n",
        "## Regex and recursion\n",
        "We will employ a recursive definition of regular expressions, as opposed to\n",
        "a more general kind of regular expression commonly used in programming languages.\n",
        "\n",
        "We define a regular expression over an alphabet (a set of allowed characters)\n",
        "$\\Sigma$ as follows.\n",
        "\n",
        "1. $\\emptyset$ and $\\varepsilon$ are regular expressions\n",
        "2. $a$ is a regular expression for all $a$ in the alphabet\n",
        "3. If $R_1, R_2$ are regular expressions, then $(R_1 | R_2)$ is a regular expression\n",
        "4. If $R_1, R_2$ are regular expressions, then $(R_1 R_2)$ is a regular expression\n",
        "5. If $R$ is a regular expression, then $R^{\\*}$ is a regular expression\n",
        "\n",
        "Semantically, we evaluate regular expressions as follows.\n",
        "1. $\\emptyset$ matches nothing, and $\\varepsilon$ matches only an empty string\n",
        "2. $a$ matches only the string containing the single character $a$\n",
        "3. $(R_1 | R_2)$ matches any string that either is matched by $R_1$ or is matched by $R_2$\n",
        "4. $(R_1 R_2)$ matches any string that can be split in two in such a way that the first\n",
        "    segment is matched by $R_1$ and the second is matched by $R_2$\n",
        "5. $R^{\\*}$ matches any string that can be split into 0 or more segments which are\n",
        "   all matched by $R$. Note that this includes the empty string\n",
        "\n",
        "We will use the following classes to represent a regular expression."
      ],
      "id": "aae1071e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class Regex:\n",
        "    name: str\n",
        "    regex: list\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        ...\n",
        "\n",
        "class Empty(Regex):\n",
        "    def __init__(self) -> None:\n",
        "        self.regex = []\n",
        "        self.name = \"Empty\"\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return \"Empty()\"\n",
        "\n",
        "class Epsilon(Regex):\n",
        "    def __init__(self) -> None:\n",
        "        self.regex = []\n",
        "        self.name = \"Epsilon\"\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return \"Epsilon()\"\n",
        "\n",
        "class Char(Regex):\n",
        "    def __init__(self, char: str) -> None:\n",
        "        assert len(char) == 1\n",
        "        assert char in ALPHABET\n",
        "        self.char = char\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f\"Char({self.char})\"\n",
        "\n",
        "class Union(Regex):\n",
        "    def __init__(self, r1: Regex, r2: Regex) -> None:\n",
        "        self.r1 = r1\n",
        "        self.r2 = r2\n",
        "        self.regex = [self.r1, self.r2]\n",
        "        self.name = \"Union\"\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f\"Union({self.r1, self.r2})\"\n",
        "\n",
        "class Concat(Regex):\n",
        "    def __init__(self, r1: Regex, r2: Regex) -> None:\n",
        "        self.r1 = r1\n",
        "        self.r2 = r2\n",
        "        self.regex = [self.r1, self.r2]\n",
        "        self.name = \"Concat\"\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f\"Concat({self.r1, self.r2})\"\n",
        "\n",
        "class Star(Regex):\n",
        "    def __init__(self, r: Regex) -> None:\n",
        "        self.r = r\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f\"Star({self.r})\""
      ],
      "id": "132a2a1a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extending the NFA class\n",
        "In this section, we will define some helper functions for the NFA class which\n",
        "will simplify the regex to NFA conversion. We want a function which will allow\n",
        "for a second NFA to be \"inserted\" into an existing NFA in such a way that any\n",
        "any incoming transitions pointing towards some specified insertion target state\n",
        "will be redirected to the initial state of the NFA being inserted, and any\n",
        "outgoing transitions will be added to the final states of the NFA being inserted.\n",
        "Additionally, the final states of the NFA being inserted should remain final\n",
        "if and only if the target insertion state was itself final in the original NFA.\n"
      ],
      "id": "91f147b4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class NFA(NFA):\n",
        "    def insert(self, state: int, nfa: NFA) -> None:  # TODO: maybe refactor to use len instead of self.next_state\n",
        "        \"\"\"\n",
        "        Assumes NFAs have their states numbered monotonically.\n",
        "\n",
        "        TODO: simplify to just delete the old target state and change transitions where necessary\n",
        "        (just add a constant to every state in the inserted NFA)\n",
        "        \"\"\"\n",
        "        # add states\n",
        "        self.states |= set(range(self.next_state, self.next_state + nfa.next_state - 1))  # TODO: dont add extra state (one is shared)\n",
        "\n",
        "        # deal with final states\n",
        "        if state in self.final:\n",
        "            if 0 not in nfa.final:\n",
        "                self.final.remove(state)\n",
        "            self.final |= {s + self.next_state - 1 for s in nfa.final - {0}}\n",
        "\n",
        "        # map nfa transitions to new values\n",
        "        nfa.transitions = {\n",
        "            state: {\n",
        "                char: set(map(lambda s: s + self.next_state - 1, targets)) for char, targets in transitions.items()\n",
        "            } for state, transitions in nfa.transitions.items()\n",
        "        }\n",
        "\n",
        "        # update transitions\n",
        "        new_transitions = {}\n",
        "        for s in range(1, nfa.next_state):\n",
        "            actual_state = s + self.next_state - 1\n",
        "            if s in nfa.final:\n",
        "                new_transitions[actual_state] = self.join_transitions(\n",
        "                    nfa.transitions[s],\n",
        "                    self.transitions[state]\n",
        "                )\n",
        "            else:\n",
        "                new_transitions[actual_state] = nfa.transitions[s]\n",
        "\n",
        "        if 0 in nfa.final:\n",
        "            new_transitions[state] = self.join_transitions(\n",
        "                nfa.transitions[0],\n",
        "                self.transitions[state]\n",
        "            )\n",
        "        else:\n",
        "            new_transitions[state] = nfa.transitions[0]\n",
        "\n",
        "        self.transitions = {**self.transitions, **new_transitions}\n",
        "        self.next_state += nfa.next_state - 1\n",
        "\n",
        "    def join_transitions(self, a: dict[str, set[int]], b: dict[str, set[int]]) -> dict[str, set[int]]:\n",
        "        return {\n",
        "            char: a.get(char, set()) | b.get(char, set()) for char in a.keys() | b.keys()\n",
        "        }"
      ],
      "id": "07a83dad",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Basic conversions\n",
        "We will begin by exploring how the base cases of regular expressions\n",
        "can be expressed as NFA.\n",
        "\n",
        "Clearly, $\\emptyset$ is equivalent to any NFA which matches no strings.\n",
        "We can achieve this by creating an NFA with a single state which is non-final.\n",
        "\n",
        "[diagram]\n"
      ],
      "id": "e4faa51c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class Empty(Empty):\n",
        "    def to_nfa(self) -> NFA:\n",
        "        return NFA()"
      ],
      "id": "ecc747a0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, consider $\\varepsilon$. In order to match only the empty string, we can construct\n",
        "an NFA where the initial state is a sole final state but reading any character forces the NFA\n",
        "to leave this state forever.\n",
        "\n",
        "[diagram]\n"
      ],
      "id": "8c180d0a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class Epsilon(Epsilon):\n",
        "    def to_nfa(self) -> NFA:\n",
        "        nfa = NFA()\n",
        "        nfa.add_state({\n",
        "            a: {1} for a in ALPHABET\n",
        "        })\n",
        "        nfa.update(0, {\n",
        "            a: {1} for a in ALPHABET\n",
        "        })\n",
        "        nfa.make_final(0)\n",
        "        return nfa"
      ],
      "id": "67008e3b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For any $a$, we can construct an NFA which accepts only the string containing a single $a$\n",
        "as follows.\n",
        "\n",
        "[diagram]\n"
      ],
      "id": "416fc1c6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class Char(Char):\n",
        "    def to_nfa(self) -> NFA:\n",
        "        nfa = NFA()\n",
        "        nfa.update(0, {\n",
        "            a: {1 if a == self.char else 2} for a in ALPHABET\n",
        "        })\n",
        "        nfa.add_state({\n",
        "            a: {2} for a in ALPHABET\n",
        "        })\n",
        "        nfa.add_state({\n",
        "            a: {2} for a in ALPHABET\n",
        "        })\n",
        "        nfa.make_final(1)\n",
        "        return nfa"
      ],
      "id": "d924b5fe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Recursive conversions\n",
        "For this section, suppose we have two regex $R_1, R_2$ with equivalent NFAs\n",
        "$N_1, N_2$.\n",
        "\n",
        "First, we want to show how to create a NFA which is equivalent to $R_1 | R_2$.\n",
        "An equivalent NFA should run $N_1$ and $N_2$ and accept if either of them accepted.\n",
        "We can achieve this by creating an NFA which non-deterministically chooses which\n",
        "NFA to run, and then runs that NFA as in the following machine:\n",
        "\n",
        "[diagram]\n"
      ],
      "id": "56824c90"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class Union(Union):\n",
        "    def to_nfa(self) -> NFA:\n",
        "        nfa = NFA()\n",
        "        nfa.update(0, {\n",
        "            EPSILON: {1, 2}\n",
        "        })\n",
        "        nfa.add_state({})\n",
        "        nfa.add_state({})\n",
        "        nfa.make_final(1)\n",
        "        nfa.make_final(2)\n",
        "        nfa.insert(1, self.r1.to_nfa())\n",
        "        nfa.insert(2, self.r2.to_nfa())\n",
        "        return nfa"
      ],
      "id": "3d58609d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we create a new start state with two $\\varepsilon$-transitions pointing to\n",
        "the initial states of $N_1$ and $N_2$. This means that before the input is read, the NFA\n",
        "will non-deterministically choose which NFA to run, so if one of the NFA will accept\n",
        "the string, the new NFA will also accept. This exactly mirrors the behaviour\n",
        "of the regex $R_1 | R_2$, which will match a string whenever either $R_1$ or $R_2$\n",
        "is able to match it.\n",
        "\n",
        "Now, we will consider the regex $R_1 R_2$. In this case, an equivalent NFA should\n",
        "run $N_1$ and at some point when $N_1$ is in a final state, non-deterministically\n",
        "start running $N_2$. Again, this corresponds to choosing some point at which to split\n",
        "the input string, and testing that $R_1$ matches the first segment and $R_2$ matches\n",
        "the second segment.\n",
        "\n",
        "We can achieve this by adding $\\varepsilon$-transitions between every final state of $N_1$\n",
        "and the initial state of $N_2$, and changing these final states in $N_1$ to non-final.\n",
        "This way, the new NFA will run $N_1$, and whenever it is in a final state it will non-deterministically\n",
        "choose whether or not it should switch to $N_2$. If it ends in a final state,\n",
        "this means at some point it non-deterministically switched from running $N_1$\n",
        "to running $N_2$, and $N_2$ ended in a final state as well.\n",
        "\n",
        "[Diagram]\n"
      ],
      "id": "b995a664"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class Concat(Concat):\n",
        "    def to_nfa(self) -> NFA:\n",
        "        nfa = NFA()\n",
        "        nfa.update(0, {\n",
        "            EPSILON: {1}\n",
        "        })\n",
        "        nfa.add_state({  # 1\n",
        "            EPSILON: {2}\n",
        "        })\n",
        "        nfa.add_state({})  # 2\n",
        "        nfa.make_final(2)\n",
        "        nfa.insert(1, self.r1.to_nfa())\n",
        "        nfa.insert(2, self.r2.to_nfa())\n",
        "        return nfa"
      ],
      "id": "ca45dd14",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we consider the regex $R_1^{\\*}$. Recall that $R_1^{\\*}$ should match\n",
        "any string that can be split up into 0 or more segments each of which are matched\n",
        "by $R_1$. Thus, we can apply a similar construction as we did in the concatenation\n",
        "case, where final states have $\\varepsilon$-transitions pointing to the initial state.\n",
        "Additionally, since the regex also matches the empty string even if $R_1$ doesn't,\n",
        "we need to make the initial state final. To do this in a nice way we will simply\n",
        "create a new initial state that is final and has a single $\\varepsilon$ transition\n",
        "pointing to the old initial state.\n",
        "\n",
        "[diagram]\n"
      ],
      "id": "4bf2d9e6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class Star(Star):\n",
        "    def to_nfa(self) -> NFA:\n",
        "        nfa = NFA()\n",
        "        nfa.update(0, {\n",
        "            EPSILON: {1}\n",
        "        })\n",
        "        nfa.add_state({\n",
        "            EPSILON: {1}\n",
        "        })\n",
        "        nfa.make_final(0)\n",
        "        nfa.make_final(1)\n",
        "        nfa.insert(1, self.r.to_nfa())\n",
        "        return nfa"
      ],
      "id": "8f5a8bd0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Converting arbitrary regex to NFAs\n",
        "Now we have learnt how to convert various types of regex into NFAs, it remains\n",
        "to tie everything together to create an algorithm for converting arbitrary regex\n",
        "to NFAs.\n",
        "\n",
        "Notice that we have described constructions for each of the cases in the definition\n",
        "of a regular expression. Thus, given any arbitrary regular expression, we can recursively\n",
        "apply the previous constructions to obtain an NFA for an arbitrary regular expression.\n",
        "\n",
        "For example, consider the regex $$(ab)^{\\*}|a$$.\n",
        "\n",
        "This regex is of the form $R_1 | R_2$, where $R_1 = (ab)^{\\*}$ and $R_2 = a$.\n",
        "\n",
        "We can construct an NFA for $a$ easily, and for $(ab)*$ it is of the from $R^{\\*}$\n",
        "so we need to first construct an NFA for $ab$. However, $ab$ is the concatenation\n",
        "of $a$ and $b$, so we get\n",
        "\n",
        "[diagram]\n",
        "\n",
        "Moreover, we have\n",
        "\n",
        "[diagrams for each]\n",
        "\n",
        "Hence, the algorithms we have already written are sufficient to construct an NFA\n",
        "from any arbitrary regex, due to their recursive definition.\n",
        "\n",
        "## Parsing regex\n",
        "Of course, one problem remains. We need to know what form the regex takes. For example,\n",
        "given the regex $$(ab)^{\\*}|a,$$ we don't immidiately know how to convert it \n",
        "into the parsed form represented by our classes.\n",
        "\n",
        "Here, I will present a simple regex parser which will correctly parse any regex\n",
        "following the definition presented earlier. In particular, the brackets must always\n",
        "be included.\n",
        "\n",
        "First, since we will be dealing with possibly nested parentheses, we will use a helper function\n",
        "which when given a string and a position of an open parenthesis in this string,\n",
        "finds the position of the matching closing parenthesis.\n"
      ],
      "id": "ee855ae5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def matching_idx(s: str, i: int) -> int:\n",
        "    if s[i] != \"(\":\n",
        "        raise ValueError(\"Initial character is not '('\")\n",
        "\n",
        "    depth = 1\n",
        "\n",
        "    for j, c in enumerate(s[i+1:], start=i+1):\n",
        "        if c == \"(\":\n",
        "            depth += 1\n",
        "        if c == \")\":\n",
        "            depth -= 1\n",
        "        if depth == 0:\n",
        "            return j"
      ],
      "id": "1c4091f0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, to actually parse... [TODO: GIVE IDEA]"
      ],
      "id": "a7752744"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def parse(s: str) -> Regex:\n",
        "    print(\"Parsing\", s)\n",
        "\n",
        "    if len(s) == 0:\n",
        "        return Epsilon()\n",
        "    if len(s) == 1:\n",
        "        if s == EPSILON:\n",
        "            return Epsilon()\n",
        "        if s not in ALPHABET:\n",
        "            raise ValueError(f\"Character '{s}' is not in the alphabet\")\n",
        "        return Char(s)\n",
        "\n",
        "    if s[0] == \"(\":\n",
        "        end_idx = matching_idx(s, 0)\n",
        "        if end_idx == -1:\n",
        "            raise ValueError(\"Could not parse regex: no matching parenthesis\")\n",
        "    else:\n",
        "        end_idx = 0\n",
        "\n",
        "    if end_idx > 0:\n",
        "        symbol = parse(s[1 : end_idx])\n",
        "    else:\n",
        "        symbol = parse(s[0])\n",
        "\n",
        "    if len(s) == end_idx + 1:\n",
        "        return symbol\n",
        "\n",
        "    next_char = s[end_idx+1]\n",
        "\n",
        "    if next_char == \"|\":\n",
        "        return Union(symbol, parse(s[end_idx+2:]))\n",
        "    elif next_char == \"*\":\n",
        "        if len(s) == end_idx + 2:\n",
        "            return Star(symbol)\n",
        "        else:\n",
        "            return Concat(Star(symbol), parse(s[end_idx+2:]))\n",
        "    elif next_char == \"(\":\n",
        "        return Concat(symbol, parse(s[end_idx+2:-1]))\n",
        "    else:\n",
        "        return Concat(symbol, parse(s[end_idx+1:]))"
      ],
      "id": "e3e196be",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion\n",
        "Finally, to tie everything together, we can write a program that will take in two\n",
        "regex strings, and determine whether or not they are equivalent.\n"
      ],
      "id": "00b718d4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "r1 = r\"(((ab)*)|a)\"\n",
        "r2 = r\"((ab)|b*)\"\n",
        "pr1, pr2 = parse(r1), parse(r2)\n",
        "n1, n2 = pr1.to_nfa(), pr2.to_nfa()\n",
        "d1, d2 = n1.determinise1(), n2.determinise1()\n",
        "# print(\"Is equivalent:\", d1.is_equivalent(d2))"
      ],
      "id": "fc3d0910",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/martin.ong/Desktop/grammar-inference/blog/regex_equivalence/venv/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}